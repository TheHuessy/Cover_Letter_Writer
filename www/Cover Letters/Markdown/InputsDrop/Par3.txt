I am very well versed in R, which began as an intro class when I started my Masters and is now an integral part of my everyday work. Where some wanted to keep using excel or SPSS to run analysis, I saw the opportunity to use R and develop not only quality statistical analysis, but also better visual representations of the data from simple ggplot outputs to shiny apps written to showcase geographical differences in data at different levels. Due in part to my policy background and skills in R, I was hired by the Boston Area Research Initiative (BARI) to head up housing and transportation data projects. Since January 2018, I have built an automated web scraper that collects, stores, and cleans Craigslist data, and most importantly I built, set up, and maintain a local storage server for BARI which is now used to back up all big data files and host local geocoding software.
